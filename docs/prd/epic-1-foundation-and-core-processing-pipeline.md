\n# Epic 1: Foundation & Core Processing Pipeline\n\n**Epic Goal:** Establish the complete technical foundation and deliver the core document conversion workflow, enabling users to upload documents, process them with Docling, and download markdown output. This epic creates a fully deployable end-to-end system with basic functionality, providing the foundation for all subsequent enhancements.\n\n## Story 1.1: Project Initialization & Repository Setup\n\nAs a **developer**,\nI want **monorepo project structure with Next.js frontend and FastAPI backend configured**,\nso that **the team has a clean foundation for parallel frontend/backend development**.\n\n### Acceptance Criteria\n\n1. Monorepo created with `/frontend` (Next.js 14 App Router) and `/backend` (FastAPI Python 3.11+) directories\n2. Frontend configured with TailwindCSS, shadcn/ui, TypeScript, ESLint, and Prettier\n3. Backend configured with FastAPI, Pydantic, pytest, Black, and Ruff formatting\n4. Git repository initialized with `.gitignore` for Node and Python, conventional commit setup, and pre-commit hooks for code formatting\n5. Both services run locally with health check endpoints (`GET /` returns 200 OK with basic JSON response)\n6. README documents local development setup for both frontend and backend services\n\n## Story 1.2: Supabase Integration & Database Schema\n\nAs a **developer**,\nI want **Supabase PostgreSQL database schema and storage buckets configured**,\nso that **the application can persist document metadata and store uploaded/processed files**.\n\n### Acceptance Criteria\n\n1. Supabase client libraries integrated (supabase-js for frontend, supabase-py for backend) with environment variable configuration\n2. Database table `documents` created with fields: `id` (UUID, PK), `filename` (text), `status` (enum: queued/processing/complete/failed), `processing_options` (JSON), `created_at` (timestamp), `completed_at` (timestamp), `error_message` (text, nullable)\n3. Two storage buckets created: `uploads` (original files) and `processed` (markdown files), both configured as private with backend-only access\n4. Backend service successfully connects to Supabase and can create test records in `documents` table\n5. Backend service can upload/download test files to/from both storage buckets with proper error handling\n6. Database migration script or schema documentation provided for reproducible setup\n\n## Story 1.3: File Upload UI & Client-Side Validation\n\nAs a **workshop attendee**,\nI want **drag-and-drop file upload interface with immediate validation feedback**,\nso that **I can easily upload my documents and know if they're acceptable before processing**.\n\n### Acceptance Criteria\n\n1. Upload screen displays large drag-and-drop zone using react-dropzone with visual hover states\n2. Click-to-browse fallback option available for users preferring traditional file selection\n3. Client-side validation enforces: file type (PDF, DOCX, PPTX, XLSX only), file size (max 10MB) with immediate visual feedback on validation failure\n4. Accepted files display filename and file size before upload confirmation\n5. Upload button triggers file transmission to backend with visual loading state (spinner/progress indicator)\n6. Responsive layout works on mobile devices with touch-friendly drop zone (minimum 44px touch targets)\n7. Clear error messages displayed for rejected files: \"Unsupported file type - only PDF, DOCX, PPTX, XLSX allowed\" or \"File too large - maximum 10MB\"\n\n## Story 1.4: Backend File Upload & Storage\n\nAs a **backend service**,\nI want **file upload endpoint that validates and stores documents in Supabase**,\nso that **uploaded files are securely stored and tracked for processing**.\n\n### Acceptance Criteria\n\n1. `POST /api/upload` endpoint accepts multipart/form-data file uploads with server-side validation (file type, size limits)\n2. Uploaded file stored in Supabase `uploads` bucket with unique filename (UUID-based to prevent collisions)\n3. Document metadata record created in `documents` table with status='queued', original filename, and processing options placeholder\n4. Endpoint returns JSON response with document `id`, `filename`, and `status`\n5. Server-side validation errors return 400 status with actionable error messages matching client-side validation messages\n6. File upload errors (storage failures) return 500 status with error logged and user-friendly message returned\n7. Unit tests verify validation logic, integration tests verify Supabase storage operations\n\n## Story 1.5: Docling Processing Pipeline\n\nAs a **backend service**,\nI want **document processing workflow using Docling to convert files to markdown**,\nso that **uploaded documents are transformed into AI-optimized format**.\n\n### Acceptance Criteria\n\n1. Docling library integrated with basic configuration (Fast mode, no OCR for initial implementation)\n2. `POST /api/process/{document_id}` endpoint triggers processing: updates status to 'processing', retrieves file from `uploads` bucket, invokes Docling conversion\n3. Docling output (markdown text) stored in Supabase `processed` bucket with matching filename pattern (`{original-name}.md`)\n4. On successful processing: status updated to 'complete', `completed_at` timestamp set, processed file path stored in metadata\n5. On processing failure: status updated to 'failed', `error_message` populated with Docling error details, original file remains in uploads bucket\n6. Processing timeout enforced at 5 minutes, triggering failure status if exceeded\n7. Unit tests mock Docling operations, integration tests verify full pipeline with sample PDF file\n\n## Story 1.6: Markdown Download & Basic Frontend Flow\n\nAs a **workshop attendee**,\nI want **to download processed markdown files after upload completes**,\nso that **I can use the converted document in Open WebUI**.\n\n### Acceptance Criteria\n\n1. Frontend polls `GET /api/status/{document_id}` endpoint every 2 seconds after upload to check processing status\n2. `GET /api/status/{document_id}` returns current status, filename, and download URL (if complete) or error message (if failed)\n3. UI transitions from \"Uploading...\" → \"Processing...\" → \"Complete\" based on status updates\n4. Download button appears when status='complete', triggering `GET /api/download/{document_id}` which streams markdown file from `processed` bucket\n5. Downloaded file preserves original filename with `.md` extension (e.g., `report.pdf` → `report.md`)\n6. \"Process Another Document\" button resets UI to upload screen after successful download\n7. Error state displays error message from backend with \"Try Again\" button returning to upload screen\n\n## Story 1.7: DigitalOcean Deployment & CI/CD\n\nAs a **developer**,\nI want **automated deployment to DigitalOcean App Platform with staging and production environments**,\nso that **the application is accessible for testing and ready for workshop use**.\n\n### Acceptance Criteria\n\n1. DigitalOcean App Platform configured with two services: `frontend` (Next.js) and `backend` (FastAPI) both deploying from monorepo\n2. Staging environment deployed with separate Supabase instance/buckets for testing\n3. Environment variables configured for both services (Supabase credentials, API URLs, file size limits)\n4. Health check endpoints (`/api/health` for backend, `/_health` for frontend) configured in DigitalOcean for monitoring\n5. Deployment succeeds for both services with publicly accessible URLs (e.g., `https://frontend.ondigitalocean.app`, `https://backend.ondigitalocean.app`)\n6. Basic smoke test passes: upload sample PDF → process → download markdown in staging environment\n7. Deployment documentatio